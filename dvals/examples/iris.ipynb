{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6824\n",
      "Epoch [20/100], Loss: 0.5442\n",
      "Epoch [30/100], Loss: 0.4747\n",
      "Epoch [40/100], Loss: 0.4320\n",
      "Epoch [50/100], Loss: 0.4027\n",
      "Epoch [60/100], Loss: 0.3811\n",
      "Epoch [70/100], Loss: 0.3642\n",
      "Epoch [80/100], Loss: 0.3504\n",
      "Epoch [90/100], Loss: 0.3386\n",
      "Epoch [100/100], Loss: 0.3284\n",
      "Test Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Define the model\n",
    "model = nn.Linear(4, 3)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss at every 10th epoch\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "to_np = lambda  mod: lambda _x: mod(_x).detach().cpu().numpy()\n",
    "prob_model = torch.nn.Sequential(model, torch.nn.Softmax(dim=-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:12.259492Z",
     "start_time": "2024-06-14T16:58:08.859221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from dvals.player_distributions import ShapleyCD\n",
    "\n",
    "# initialize shapley coalition distribution and baseline\n",
    "scd = ShapleyCD(4)\n",
    "baseline = torch.mean(X_train, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:14.344569Z",
     "start_time": "2024-06-14T16:58:14.327447Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([ 0.16921091, -0.11419018, -0.05502074], dtype=float32), 1: array([ 0.18676063, -0.1640841 , -0.02267651], dtype=float32), 2: array([ 0.32333717, -0.25545856, -0.06787854], dtype=float32), 3: array([ 0.05509668,  0.01608855, -0.07118523], dtype=float32)}\n",
      "\n",
      "[0.2526324  0.5301747  0.21719286]\n",
      "\n",
      "[9.8703778e-01 1.2530354e-02 4.3182765e-04]\n"
     ]
    }
   ],
   "source": [
    "from dvals import values\n",
    "from dvals.games import game_from_ml_model_with_baseline_torch\n",
    "\n",
    "standard_svs = []\n",
    "# computes exact Shapley values for all exampls\n",
    "for x in X_train:\n",
    "    std_prob_game = game_from_ml_model_with_baseline_torch(to_np(prob_model), x, baseline)\n",
    "    svs = values.compute(std_prob_game, scd, False)\n",
    "    standard_svs.append(svs)\n",
    "# print a value, just to show\n",
    "print(standard_svs[0], standard_svs[0].offset, standard_svs[0].grand_payoff, sep='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:14.918014Z",
     "start_time": "2024-06-14T16:58:14.720237Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: <CategoricalDifference {(0, 1): 0.12128063469056204, (0, 2): 0.04793030369147252, (1, 0): 0.0, (1, 2): 0.007090438858103076, (2, 0): 0.0, (2, 1): 0.0, 0.0: 0.8236986185802379}>, 1: <CategoricalDifference {(0, 1): 0.15942370363651215, (0, 2): 0.02733691485299056, (1, 0): 0.0, (1, 2): 0.0, (2, 0): 0.0, (2, 1): 0.004660402174145157, 0.0: 0.8085789556983703}>, 2: <CategoricalDifference {(0, 1): 0.2561276663496523, (0, 2): 0.06720949407412533, (1, 0): 0.0, (1, 2): 0.0006690683695424548, (2, 0): 0.0, (2, 1): 0.0, 0.0: 0.6759938055523282}>, 3: <CategoricalDifference {(0, 1): 0.016440963249083004, (0, 2): 0.03865572472344579, (1, 0): 0.0, (1, 2): 0.032529512721613495, (2, 0): 0.0, (2, 1): 0.0, 0.0: 0.9123738327325555}>}\n",
      "\n",
      "<CategoricalPayoff {0: 0.25263244, 1: 0.5301747, 2: 0.21719287}>\n"
     ]
    }
   ],
   "source": [
    "from dvals.games import CategoricalGame\n",
    "\n",
    "# computes the categorical values\n",
    "cat_svs = []\n",
    "for x in X_train:\n",
    "    std_logits_game = game_from_ml_model_with_baseline_torch(to_np(model), x, baseline)\n",
    "    cat_game = CategoricalGame.from_logits_game(std_logits_game)\n",
    "    rs = cat_game([set(), {0, 1, 2, 3}])\n",
    "    cat_sv = values.compute(cat_game, scd, False)\n",
    "    cat_svs.append(cat_sv)\n",
    "# print a categorical value!\n",
    "print(cat_svs[0], cat_svs[0].offset, sep='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:15.566373Z",
     "start_time": "2024-06-14T16:58:15.101691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def importance_standard_abs(val):\n",
    "    importance = np.sum(np.abs(val.np_values(include_offset=False, include_gp=False)), axis=1)\n",
    "    srt = np.argsort(importance)[::-1]\n",
    "    return importance, srt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:15.589238Z",
     "start_time": "2024-06-14T16:58:15.586761Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def dval_importance(dval):\n",
    "    importance = np.array([dval[i].probability_of_change() for i in range(4)])\n",
    "    srt = np.argsort(importance)[::-1]\n",
    "    return importance, srt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:16.050364Z",
     "start_time": "2024-06-14T16:58:16.048076Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Identifying cancellation errors of standard SVs\n",
    "\n",
    "This addresses the fact that standard SVs are expectations $\\mathbb{E}_S [v(S\\cup i) - v(S)]$.\n",
    "Simple fact, the expectation can \"hide\" importance as you might have terms that cancel each other out.\n",
    "e.g. for binary classifiers, 2 features problem you can have simple attributions of -1 and 1 that cancel each other out, leaving as output 0. However, one would hardly say that that feature is unimportant, as it always flip the outcome. Bernoulli values correctly identify that that feature is relevant by putting $Q(\\xi = 0) = 0$.\n",
    "This is an extreme case, but in practice what it is easy to verify is that cancellations lead to wrong attribution orders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ids_for_cancellation_all = []\n",
    "ids_for_cancellation_first = []\n",
    "for k, (stv, catv) in enumerate(zip(standard_svs, cat_svs)):\n",
    "    _, st_ord = importance_standard_abs(stv)\n",
    "    _, cat_ord = dval_importance(catv)\n",
    "    if np.any(st_ord != cat_ord):\n",
    "        ids_for_cancellation_all.append(k)\n",
    "    if st_ord[0] != cat_ord[0]:\n",
    "        ids_for_cancellation_first.append(k)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:16.901332Z",
     "start_time": "2024-06-14T16:58:16.891613Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(120, 18, 4)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(ids_for_cancellation_all), len(ids_for_cancellation_first)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T16:58:17.290191Z",
     "start_time": "2024-06-14T16:58:17.286003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
